{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob                                # Parcourir dossier de dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2                                           # traitement des images du dataset\n",
    "from keras.datasets import mnist                     # Importe le dataset de mnist\n",
    "from keras.utils import to_categorical               # pour modifier les labels\n",
    "from keras.models import Sequential, load_model      # type de modele\n",
    "from keras.layers import Dense, Flatten              # Fully Connected Layers\n",
    "from keras.layers import Conv2D, MaxPooling2D        # Convolutional layers + Maxpooling layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy    # Loss function\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import h5py                                          # Pour pouvoir enregistrer son modele en .h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection of handwritten digits with MNIST\n",
    "\n",
    "MNIST est un exemple très souvent utilisé pour commencer avec les CNN, son dataset existe sur keras et peut être directement importé avec la fonction **load_data( )**\n",
    "\n",
    "Note :\n",
    "- Le dataset de MNIST a 60 000 exemples d'entrainement et 10 000 exemples de training\n",
    "- Le format de chaque image est de 28x28 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## STEP 1 : Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les données sont déjà séparées en training set et testing set sur keras\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez voir à quoi ressemble votre dataset avec un print. A noter que votre x_train est une liste [ ] de 60 000 exemples et que votre x_test est une liste de 10 000 exemples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chaque exemple se compose de 28 listes de 28 valeurs (car 28x28 pixels), il y a donc 28x28 = 784 valeurs, une par pixel\n",
    "- Chaque pixel a une valeur comprise entre 0 et 255, car un int = 8 octets donc 2^8 = 256 valeurs possibles, mais on commence à zéro donc 0-255\n",
    "- Les labels sont une valeur unique comprise entre 0 et 9 et correspondent au digit de l'image en question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez verifier la shape de votre dataset (x_train, x_test, y_train et y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 : Prepare Data\n",
    "\n",
    "\n",
    "Ensuite, une fois les données importées, nous devons les préparer afin qu'elles puissent être données à notre modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous allons ajouter une dimension à la fin de nos x_train et x_test pour préciser le nombre de canaux que nous utiliserons.\n",
    "\n",
    "- 1 pour Noir et Blanc\n",
    "- 3 pour RGB\n",
    "- L pour nuances de gris\n",
    "\n",
    "Pour cet exemple, nous nous contenterons d'une image en N&B, donc la valeur de notre dimension supplémentaire sera égale à 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape : (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1) # x_train.shape[0] = 60 000, 1 pour B&W\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1) # x_test.shape[0] = 10 000, 1 pour B&W\n",
    "\n",
    "# Verifier qu'une dimension a bien été ajoutée et que sa valeur = 1\n",
    "\n",
    "print ('x_train shape :', x_train.shape)\n",
    "print (x_train.shape[0], \"train samples\")\n",
    "print (x_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayez de print un exemple du x_train pour voir à quoi cela ressemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  5]\n",
      "  [ 63]\n",
      "  [197]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 20]\n",
      "  [254]\n",
      "  [230]\n",
      "  [ 24]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 20]\n",
      "  [254]\n",
      "  [254]\n",
      "  [ 48]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 20]\n",
      "  [254]\n",
      "  [255]\n",
      "  [ 48]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 20]\n",
      "  [254]\n",
      "  [254]\n",
      "  [ 57]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 20]\n",
      "  [254]\n",
      "  [254]\n",
      "  [108]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 16]\n",
      "  [239]\n",
      "  [254]\n",
      "  [143]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [178]\n",
      "  [254]\n",
      "  [143]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [178]\n",
      "  [254]\n",
      "  [143]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [178]\n",
      "  [254]\n",
      "  [162]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [178]\n",
      "  [254]\n",
      "  [240]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [113]\n",
      "  [254]\n",
      "  [240]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 83]\n",
      "  [254]\n",
      "  [245]\n",
      "  [ 31]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 79]\n",
      "  [254]\n",
      "  [246]\n",
      "  [ 38]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [214]\n",
      "  [254]\n",
      "  [150]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [144]\n",
      "  [241]\n",
      "  [  8]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [144]\n",
      "  [240]\n",
      "  [  2]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [144]\n",
      "  [254]\n",
      "  [ 82]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [230]\n",
      "  [247]\n",
      "  [ 40]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [168]\n",
      "  [209]\n",
      "  [ 31]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]]\n",
      "label x_train[8] = 1\n"
     ]
    }
   ],
   "source": [
    "print(x_train[8])\n",
    "print('label x_train[8] =', y_train[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous allons normaliser notre dataset afin que les valeurs de nos pixels soient comprises entre 0 et 1 plutôt qu'entre 0 et 255. Cela facilitera les calculs pour la machine.\n",
    "\n",
    "Pour se faire, il faudra d'abord \"recaster\" nos variables *x_train* et *x_test* en tant que float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recast\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.01960784]\n",
      "  [0.24705882]\n",
      "  [0.77254903]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07843138]\n",
      "  [0.99607843]\n",
      "  [0.9019608 ]\n",
      "  [0.09411765]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07843138]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.1882353 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07843138]\n",
      "  [0.99607843]\n",
      "  [1.        ]\n",
      "  [0.1882353 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07843138]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.22352941]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07843138]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.42352942]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.0627451 ]\n",
      "  [0.9372549 ]\n",
      "  [0.99607843]\n",
      "  [0.56078434]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.69803923]\n",
      "  [0.99607843]\n",
      "  [0.56078434]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.69803923]\n",
      "  [0.99607843]\n",
      "  [0.56078434]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.69803923]\n",
      "  [0.99607843]\n",
      "  [0.63529414]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.69803923]\n",
      "  [0.99607843]\n",
      "  [0.9411765 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.44313726]\n",
      "  [0.99607843]\n",
      "  [0.9411765 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.3254902 ]\n",
      "  [0.99607843]\n",
      "  [0.9607843 ]\n",
      "  [0.12156863]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.30980393]\n",
      "  [0.99607843]\n",
      "  [0.9647059 ]\n",
      "  [0.14901961]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.8392157 ]\n",
      "  [0.99607843]\n",
      "  [0.5882353 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.5647059 ]\n",
      "  [0.94509804]\n",
      "  [0.03137255]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.5647059 ]\n",
      "  [0.9411765 ]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.5647059 ]\n",
      "  [0.99607843]\n",
      "  [0.32156864]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.9019608 ]\n",
      "  [0.96862745]\n",
      "  [0.15686275]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.65882355]\n",
      "  [0.81960785]\n",
      "  [0.12156863]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]]\n",
      "label x_train[8] = 1\n"
     ]
    }
   ],
   "source": [
    "print(x_train[8])\n",
    "print('label x_train[8] =', y_train[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant qu'on a bien modifié nos training et testing sets, il nous reste à modifier nos labels de façon à ce que la machine puisse mieux les comprendre.\n",
    "\n",
    "Pour l'instant, notre y_train est une liste de 60 000 valeurs entre 0 et 9, qui sont les labels des images correspondantes. \n",
    "\n",
    "*y_train[8] = label de la 9ème image de notre dataset, x_train[8]*\n",
    "\n",
    "Plutôt que d'avoir un label qui soit une valeur comprise entre 0 et 9, on va préférer avoir un label qui a la forme d'un one-hot vecteur. C'est à dire un vecteur composé de 10 valeurs (0 ou 1), avec un 1 a la position correspondante au label, et des 0 partout ailleurs.\n",
    "\n",
    "*Exemple : on veut transformer un* **y_train[8] = 1** en **y_train[8] = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]**\n",
    "\n",
    "On va utiliser une fonction de keras appelée **to_categorical(a, b)** qui prend en paramètre :\n",
    "- a = la liste qu'on cherche à changer\n",
    "- b = le nombre de sorties que nous avons\n",
    "\n",
    "Note : Cette fonction saura automatiquement où placer le 1 dans votre vecteur. Vous devez donc juste lui donner le nombre de catégories possibles que notre modèle pourra avoir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label x_train[8] = [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print('label x_train[8] =', y_train[10:20])\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 : Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nos données sont prêtes, nous allons pouvoir créer notre modèle. Keras a énormément de fonctions qui nous permettent d'éviter d'avoir à recoder nos fonctions de loss ou de backpropagation, pour l'objectif de cet exercice, nous allons donc les utiliser :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons commencer par définir une variable en tant que modèle en utilisant la méthode Sequential de keras. Utiliser cette méthode nous facilitera le travail pour ajouter nos couches et train notre modèle. Pour plus d'infos vous pouvez checker la doc\n",
    "\n",
    "https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons notre modèle, nous pouvons y ajouter les couches donc nous avons besoin. Rappelez vous l'ordre des couches (D'abord les couches de conv, puis les couches de Maxpool, puis les Fully Connected)\n",
    "\n",
    "Pour ajouter une couche, vous pouvez utiliser la fonction **.add( )**\n",
    "\n",
    "Attention : Pour la première couche, n'oubliez pas qu'il faut préciser l'*input_shape*\n",
    "\n",
    "Voici la doc qui vous aidera à utiliser votre model Sequential https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "Vous pouvez utiliser la fonction **.summary( )** pour voir les détails de vos couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /sgoinfre/goinfre/Perso/epham/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 329,962\n",
      "Trainable params: 329,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "# Ajouter les couches de convolution\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Ajouter les couches de MaxPooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Alterner entre couche de convolution et maxpooling\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Applatir le dataset en un seul array\n",
    "model.add(Flatten())\n",
    "\n",
    "# Ajouter les couches Fully Connected\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# Ajouter la dernière couche FC, mais avec cette fois le nombre de sorties au lieu du nombre de neurones\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilation du modèle avant l'entrainement\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4 : Train Model and save it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous devons maintenant entrainer notre modèle afin de voir ses performances. Pour cela, vous pouvez utiliser la fonction **.fit( )** qui prend en paramètres :\n",
    "- x_train\n",
    "- y_train,\n",
    "- votre taille de batch\n",
    "- votre nombre d'epochs\n",
    "- votre proportion de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /sgoinfre/goinfre/Perso/epham/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 71s 1ms/step - loss: 0.1978 - acc: 0.9372 - val_loss: 0.0567 - val_acc: 0.9840\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 69s 1ms/step - loss: 0.0464 - acc: 0.9857 - val_loss: 0.0479 - val_acc: 0.9864\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 69s 1ms/step - loss: 0.0308 - acc: 0.9904 - val_loss: 0.0359 - val_acc: 0.9895\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 70s 1ms/step - loss: 0.0229 - acc: 0.9927 - val_loss: 0.0479 - val_acc: 0.9855\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 69s 1ms/step - loss: 0.0180 - acc: 0.9944 - val_loss: 0.0357 - val_acc: 0.9902\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 69s 1ms/step - loss: 0.0138 - acc: 0.9956 - val_loss: 0.0351 - val_acc: 0.9906\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 69s 1ms/step - loss: 0.0124 - acc: 0.9959 - val_loss: 0.0383 - val_acc: 0.9907\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 70s 1ms/step - loss: 0.0091 - acc: 0.9968 - val_loss: 0.0459 - val_acc: 0.9897\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 71s 1ms/step - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0360 - val_acc: 0.9925\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 70s 1ms/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.0456 - val_acc: 0.9888\n",
      "10000/10000 [==============================] - 5s 461us/step\n",
      "[0.03550882052455672, 0.9901]\n"
     ]
    }
   ],
   "source": [
    "# Pour ceux qui veulent approfondir, vous pouvez checker l'utilisation de tensorboard\n",
    "tbd = TensorBoard(\n",
    "    log_dir='tensorboard', histogram_freq=0,\n",
    "    write_graph=True, write_images=True\n",
    ")\n",
    "\n",
    "# Entrainement du modèle\n",
    "h = model.fit(x_train, y_train, batch_size=128, verbose=1, epochs=10, validation_split=0.2, callbacks=[tbd])\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "print(score)\n",
    "\n",
    "# Save le modèle\n",
    "model.save(\"cnn_maxime.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x143886fd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "historydf = pd.DataFrame(h.history, index=h.epoch)\n",
    "historydf.plot(ylim=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5 : Testing our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons un modèle, nous allons pouvoir le tester. Pour cela, nous allons créer nos propres images de digits en blanc sur noir en allant sur ce site : https://www.piskelapp.com/\n",
    "- Cliquer sur *Create Sprite* en haut à droite\n",
    "- Dans les paramètres, resize l'image à 28x28\n",
    "- Dessinez le digit que vous voulez tester (n'hésitez pas à en faire plusieurs)\n",
    "- Exportez votre image (icone de la montagne)\n",
    "- Vérifiez que vous êtes bien sous l'onglet PNG, et cliquez sur *Download Selected frame export*\n",
    "\n",
    "Ensuite, une fois toutes vos images téléchargées, renommez les avec leur label correspondant (ce sera plus simple de vérifier le résultat), ex : image de 0 sera nommée 0.png\n",
    "  \n",
    "Mettez toutes vos images dans le même dossier que votre jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour aller chercher les images à tester, nous allons utiliser un module appelé **glob** qui se situe déjà dans vos imports.\n",
    "  \n",
    "Il faudra ensuite faire les mêmes modifications que nous avons faites à notre dataset dans le *STEP 2 : Prepare dataset* (reshape, normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 329,962\n",
      "Trainable params: 329,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0b.png prediction is : 0\n",
      "1b.png prediction is : 1\n",
      "2b.png prediction is : 2\n",
      "3b.png prediction is : 3\n",
      "4b.png prediction is : 4\n",
      "5b.png prediction is : 5\n",
      "6b.png prediction is : 6\n",
      "7b.png prediction is : 3\n",
      "8b.png prediction is : 8\n",
      "9b.png prediction is : 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Recupérer toutes nos images\n",
    "all_images = glob('*.png')\n",
    "\n",
    "model = load_model('cnn_maxime.h5')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Loop in all_images to process each image\n",
    "for image in all_images :\n",
    "    # Open the image using PLT Image.open\n",
    "    img = cv2.imread(image, 0)\n",
    "    \n",
    "    # Print the image to see\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    # Reshape the image, adding one dimension at the end\n",
    "    img = img.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    # Recast and normalize\n",
    "    img = img.astype('float32')\n",
    "    img /= 255\n",
    "    \n",
    "    # Get prediction\n",
    "    prediction = model.predict(img)\n",
    "    # Get highest value index\n",
    "    \n",
    "    prediction = np.argmax(prediction)\n",
    "    \n",
    "    print(image, 'prediction is :', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
